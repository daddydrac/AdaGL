# AdaGL
AdaGL is a deep learning optimizer that combines fractional-order calculus with adaptive techniques. Using Grünwald–Letnikov derivatives. It avoids local minima, targets flat minima, and outperforms Adam and SGD.
